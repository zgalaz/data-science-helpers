{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure helpers functionality can be imported\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_path, _ = os.path.split(os.getcwd())\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install sklearn\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Import libraries\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from helpers.utils.logger import Logger\n",
    "\n",
    "# Set the random generator seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate an example classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_classifier(X,\n",
    "                              y,\n",
    "                              model,\n",
    "                              threshold=0.5,\n",
    "                              metrics=(\"mcc\", \"acc\", \"sen\", \"spe\"),\n",
    "                              num_folds=10,\n",
    "                              num_repetitions=20,\n",
    "                              seed=42,\n",
    "                              logger=None):\n",
    "    \"\"\"\n",
    "    Cross-validate the binary classification model\n",
    "\n",
    "    This function cross-validates the input classification model using X, y. The\n",
    "    cross-validation is sed by num_folds and num_repetitions. After the model is\n",
    "    cross-validated, several metrics are computed\n",
    "\n",
    "    Supported classifications metrics:\n",
    "     - Matthews correlation coefficient (mcc)\n",
    "     - accuracy (acc)\n",
    "     - sensitivity (sen)\n",
    "     - specificity (spe)\n",
    "     - precision (pre)\n",
    "     - recall (rec)\n",
    "     - F1 score (f1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    X : numpy array\n",
    "        2D feature matrix (rows=observations, cols=features)\n",
    "\n",
    "    y : numpy array\n",
    "        1D labels array\n",
    "\n",
    "    model : class that implements fir, and predict methods\n",
    "        Initialized binary classification model\n",
    "\n",
    "    threshold : float, optional, default 0.5\n",
    "        Threshold for encoding the predicted probability as a class label\n",
    "\n",
    "    metrics : tuple, optional, default (\"mcc\", \"acc\", \"sen\", \"spe\")\n",
    "        Tuple with classification metrics to compute\n",
    "\n",
    "    num_folds : int, optional, default 10\n",
    "        Number of cross-validation folds\n",
    "\n",
    "    num_repetitions : int, optional, default 20\n",
    "        Number of cross-validation runs\n",
    "\n",
    "    seed : int, optional, default 42\n",
    "        Random generator seed\n",
    "\n",
    "    logger : Logger, optional, default None\n",
    "        Logger class\n",
    "\n",
    "    verbose: bool, optional, default False\n",
    "        Verbose switch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Default dictionary with keys=metric names, vals=metric arrays\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "\n",
    "    TypeError\n",
    "        Raised when X or y is not an instance of np.ndarray\n",
    "\n",
    "    ValueError\n",
    "        Raised when X and y have not the same number of rows (observations)\n",
    "    \"\"\"\n",
    "\n",
    "    if not all((isinstance(X, np.ndarray), isinstance(y, np.ndarray))):\n",
    "        raise TypeError('Input arrays must be of type np.ndarray')\n",
    "    if not X.shape[0] == y.shape[0]:\n",
    "        raise ValueError('Input arrays must have the same number of rows (observations)')\n",
    "\n",
    "    # Prepare the logger\n",
    "    logger = logger if logger else Logger(inspect.currentframe().f_code.co_name)\n",
    "\n",
    "    # Prepare the classification metrics dict\n",
    "    cls_metrics = {\n",
    "        \"mcc\": matthews_corrcoef,\n",
    "        \"acc\": accuracy_score,\n",
    "        \"sen\": sensitivity_score,\n",
    "        \"spe\": specificity_score,\n",
    "        \"pre\": precision_score,\n",
    "        \"rec\": recall_score,\n",
    "        \"f1\": f1_score\n",
    "    }\n",
    "\n",
    "    # Prepare the results table for the cross-validation results\n",
    "    table_cv_data = defaultdict(list)\n",
    "\n",
    "    # Prepare counter for poor prediction skips\n",
    "    num_skips = 0\n",
    "\n",
    "    # Run the desired number of cross-validation repetitions\n",
    "    for repetition in range(num_repetitions):\n",
    "\n",
    "        # Get the cross-validation indices\n",
    "        kfolds = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "        nfolds = 1\n",
    "\n",
    "        # Cross-validate the classifier\n",
    "        for train_index, test_index in kfolds.split(X, y):\n",
    "\n",
    "            try:\n",
    "\n",
    "                # Split the data to train, test sets\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                # fit the classifier\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate the classifier\n",
    "                predicted = model.predict(X_test)\n",
    "\n",
    "                # Encode the labels\n",
    "                y_true = pd.Series(y_test, dtype=np.int16)\n",
    "                y_pred = pd.Series([0 if y_hat < threshold else 1 for y_hat in predicted], dtype=np.int16)\n",
    "\n",
    "                # Compute the classification metrics\n",
    "                for metric in metrics:\n",
    "                    if metric in cls_metrics:\n",
    "                        table_cv_data[metric].append(cls_metrics[metric](y_true, y_pred))\n",
    "\n",
    "            except Exception as e:\n",
    "                if \"Input contains NaN, infinity or a value too large\" in str(e):\n",
    "                    logger.warning('Poor performance for {}/{} validation fold'.format(nfolds, num_folds))\n",
    "                    num_skips += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    logger.exception(e)\n",
    "\n",
    "            finally:\n",
    "                nfolds += 1\n",
    "\n",
    "    # Inform about poor performance skips\n",
    "    if num_skips > 0:\n",
    "        logger.info(\"{}/{} validation folds skipped (performance)\".format(num_skips, num_folds * num_repetitions))\n",
    "\n",
    "    return table_cv_data\n",
    "\n",
    "\n",
    "def sensitivity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute classification sensitivity score\n",
    "\n",
    "    Classification sensitivity (also named true positive rate or recall) measures\n",
    "    the proportion of actual positives (class 1) that are correctly identified as\n",
    "    positives. It is defined as follows:\n",
    "\n",
    "                     TP\n",
    "    sensitivity = ---------\n",
    "                   TP + FN\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    y_true : numpy array\n",
    "        1D labels array of ground truth labels\n",
    "\n",
    "    y_pred : numpy array\n",
    "        1D labels array of predicted labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Score value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the sensitivity score\n",
    "    return recall_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute classification specificity score\n",
    "\n",
    "    Classification specificity (also named true negative rate) measures the\n",
    "    proportion of actual negatives (class 0) that are correctly identified\n",
    "    as negatives. It is defined as follows:\n",
    "\n",
    "                     TN\n",
    "    specificity = ---------\n",
    "                   TN + FP\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    y_true : numpy array\n",
    "        1D labels array of ground truth labels\n",
    "\n",
    "    y_pred : numpy array\n",
    "        1D labels array of predicted labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Score value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Compute the specificity score\n",
    "    return tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Cross-validation results:\n",
      "-------------------------\n",
      "\n",
      "acc = 0.94 +- 0.02\n",
      "sen = 0.96 +- 0.04\n",
      "spe = 0.91 +- 0.07\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier\n",
    "classifier = LogisticRegression(random_state=seed, solver=\"lbfgs\")\n",
    "\n",
    "# Define the classification options\n",
    "threshold = 0.5\n",
    "metrics = (\"acc\", \"sen\", \"spe\")\n",
    "num_folds = 10\n",
    "num_repetitions = 20\n",
    "verbose = False\n",
    "\n",
    "# Cross-validate the classifier\n",
    "results = cross_validate_classifier(X, \n",
    "                                    y, \n",
    "                                    classifier, \n",
    "                                    threshold=threshold, \n",
    "                                    metrics=metrics, \n",
    "                                    num_folds=num_folds, \n",
    "                                    num_repetitions=num_repetitions, \n",
    "                                    seed=seed)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"-------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "for metric in metrics:\n",
    "    print(\"{} = {:.2f} +- {:.2f}\".format(metric, float(np.mean(results[metric])), float(np.std(results[metric]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
